{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c49a70-4deb-4f19-8eb6-fff129a473dc",
   "metadata": {},
   "source": [
    "# Azure ML Model Monitoring Demo - Production Data Simulation\n",
    "\n",
    "Series of sample notebooks designed to showcase [AML's continuous model monitoring capabilities](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-model-performance?view=azureml-api-2&tabs=azure-cli). The series of notebooks in this repo have been developed to perform core operations including model training, deployment, simulated production data scoring, and inference data collection. These notebooks have been designed to be run in order and include the following steps:\n",
    "\n",
    "- 00. Data Upload - Load time-series weather data from a local CSV into an AML datastore, and register as training & evaluation datasets\n",
    "- 01. Model Training - Train a custom temperature prediction regression model using Mlflow & Scikit-Learn and register into your AML workspace\n",
    "- 02. Model Deployment - Deploy your newly trained model to a Managed Online Endpoint with production data collection configured.\n",
    "- <b>03. Production Data Simulation - Send time-series data to your endpoint at a slow rate to simulate production inferencing. All submitted data will be collected automatically.</b>\n",
    "- 04. Monitoring Configuration - Configure a production model data monitor looking for drift in inferencing data, and scored results which can indicate that retraining should be performed.\n",
    "- 05. Offline Monitoring - Sample notebook showcasing how to identify drift in data from datasets scored outside of Azure ML.\n",
    "\n",
    "<b>This notebook utilizes the previously registered `Temperature_Prediction_Model` deployed to the endpoint `temp-pred-endpoint` and submits all weather data points to it for scoring. Here we have configured data to be scored on an extended timeline (~6 days) to simulate ongoing production data inferencing. Over time, these data will begin to drift as later months are reflected.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef73221-eb31-46cc-9e54-bcc1976bd7a4",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2228d4f-3a9d-40de-9d7c-66df590d8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Environment, CodeConfiguration, DataCollector, DeploymentCollection\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from mlflow import set_tracking_uri\n",
    "import mlflow\n",
    "import mltable\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093997aa-27ab-4d7a-9f71-ca7d9af04f24",
   "metadata": {},
   "source": [
    "### Establish connection to Azure ML workspace using the v2 SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370bf49-66b7-4ad1-90f1-2217aa52d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<your_subscription_id>\"\n",
    "resource_group = \"<your_resource_group>\"\n",
    "workspace_name = \"<your_workspace_name>\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n",
    "workspace = ml_client.workspaces.get(workspace_name)\n",
    "tracking_uri = workspace.mlflow_tracking_uri\n",
    "\n",
    "set_tracking_uri(tracking_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a01bf-6238-4b48-8b0a-2097f8ee72d8",
   "metadata": {},
   "source": [
    "### Set environment variables\n",
    "\n",
    "Set environment variables for your endpoint URI and key which can be retrieved from your AML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e442a6-486d-4903-a387-7e4a0ce82b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ENDPOINT_URI'] = '<YOUR-ENDPOINT-URI>'\n",
    "os.environ['ENDPOINT_KEY'] = '<YOUR-ENDPOINT-KEY>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863292cc-4285-43aa-9781-57141410a72e",
   "metadata": {},
   "source": [
    "### Load complete registered weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a2e70-2b76-45af-93ca-07629a600846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "\n",
    "dataset_name = 'weather-full-data'\n",
    "\n",
    "data = ml_client.data.get(dataset_name, version='5')\n",
    "dataset = mltable.from_delimited_files(paths=[{'pattern': data._referenced_uris[0]}])\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df = df.drop(columns=['temperature'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a18f3-8fbf-4918-aa99-cf5962b38830",
   "metadata": {},
   "source": [
    "### Score all data over an extended period\n",
    "\n",
    "Iterate over all datapoints and send to the AML endpoint with a delay between each submission. The implemented delay will result in all data being scored over the period of ~6 days, but can be adjusted up/down as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19b44c-3740-427d-8efa-ea7148f1cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def submit_request(row):\n",
    "    ind_df = pd.DataFrame([row])\n",
    "    url = os.environ['ENDPOINT_URI']\n",
    "    # Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "    api_key = os.environ['ENDPOINT_KEY']\n",
    "    if not api_key:\n",
    "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "    # The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "    # Remove this header to have the request observe the endpoint traffic rules\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\n",
    "    \n",
    "    resp = requests.post(url, headers=headers, data=json.dumps({'data': ind_df.to_dict(orient='records')}))\n",
    "\n",
    "total_requests = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        submit_request(row)\n",
    "        total_requests+=1\n",
    "        if total_requests%100==0:\n",
    "            print(total_requests)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    time.sleep(15)\n",
    "   \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
