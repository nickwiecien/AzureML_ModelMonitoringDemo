{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130b4a0e-6447-497d-abe2-4acdd11b14c5",
   "metadata": {},
   "source": [
    "# Azure ML Model Monitoring Demo - Model Training\n",
    "\n",
    "Series of sample notebooks designed to showcase [AML's continuous model monitoring capabilities](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-model-performance?view=azureml-api-2&tabs=azure-cli). The series of notebooks in this repo have been developed to perform core operations including model training, deployment, simulated production data scoring, and inference data collection. These notebooks have been designed to be run in order and include the following steps:\n",
    "\n",
    "- 00. Data Upload - Load time-series weather data from a local CSV into an AML datastore, and register as training & evaluation datasets\n",
    "- <b>01. Model Training - Train a custom temperature prediction regression model using Mlflow & Scikit-Learn and register into your AML workspace</b>\n",
    "- 02. Model Deployment - Deploy your newly trained model to a Managed Online Endpoint with production data collection configured.\n",
    "- 03. Production Data Simulation - Send time-series data to your endpoint at a slow rate to simulate production inferencing. All submitted data will be collected automatically.\n",
    "- 04. Monitoring Configuration - Configure a production model data monitor looking for drift in inferencing data, and scored results which can indicate that retraining should be performed.\n",
    "- 05. Offline Monitoring - Sample notebook showcasing how to identify drift in data from datasets scored outside of Azure ML.\n",
    "\n",
    "<b>This notebook utilizes the previously registered `weather-training-data` dataset to train a custom regression model for predicting temperature based on other environmental attributes. Here, we train and register a model (`Temperature_Prediction_Model`) using Mlflow and Scikit-learn and have incorporated preprocessing logic into a scikit pipeline for seamless inferencing once deployed. After training our model, we will also score and save ALL training and evaluation data for post hoc analyses.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee2e69-de77-4379-b2f7-211faf55a107",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b67c6-55ca-43be-b5c6-f7f4e55467e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from mlflow import set_tracking_uri\n",
    "import mltable\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azureml.fsspec import AzureMachineLearningFileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3371fd-591a-4e56-9126-5bfb41628b6f",
   "metadata": {},
   "source": [
    "### Install missing packages/updated versions of mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775548f4-849b-44ba-a3c2-cfe73cca99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-ai-ml mlflow==1.30.0 mlflow-skinny==1.30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13c5ad-b977-43df-a4e8-461afe83a085",
   "metadata": {},
   "source": [
    "### Establish connection to AML workspace using the v2 SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c30d1-06b1-443c-9a79-214e1d4f007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<your_subscription_id>\"\n",
    "resource_group = \"<your_resource_group>\"\n",
    "workspace_name = \"<your_workspace_name>\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n",
    "workspace = ml_client.workspaces.get(workspace_name)\n",
    "tracking_uri = workspace.mlflow_tracking_uri\n",
    "\n",
    "set_tracking_uri(tracking_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a7b6b-9b76-4568-b39b-c7fd18ebd051",
   "metadata": {},
   "source": [
    "### Retrieve training dataset from AML workspace and load into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1e1a6-c2e7-44a9-ada3-0717f0a06541",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'weather-training-data'\n",
    "\n",
    "data = ml_client.data.get(dataset_name, version='5')\n",
    "dataset = mltable.from_delimited_files(paths=[{'pattern': data._referenced_uris[0]}])\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9c823-a305-47e9-9667-f0bd587170ea",
   "metadata": {},
   "source": [
    "### Create an experiment and submit a training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14ddfe-6803-47db-a4e2-f5460c70527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "mlflow.autolog(log_input_examples=True, log_model_signatures=True)\n",
    "\n",
    "experiment_name = 'Temperature_Prediction_Model_Training'\n",
    "run_name = 'Random_Forest_Regressor_Trial'\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "run_id = None\n",
    "\n",
    "X = df.drop('temperature', axis=1)  \n",
    "y = df['temperature']  \n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    \n",
    "    from sklearn.compose import ColumnTransformer  \n",
    "    from sklearn.pipeline import Pipeline  \n",
    "    from sklearn.impute import SimpleImputer  \n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder  \n",
    "    from sklearn.ensemble import RandomForestRegressor  \n",
    "    from sklearn.model_selection import train_test_split  \n",
    "\n",
    "\n",
    "    # # Dynamically select numerical and categorical features  \n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64', 'int32']).columns  \n",
    "    categorical_features = X.select_dtypes(include=['object']).columns  \n",
    "\n",
    "    # # Define preprocessing for numeric columns (scale them)  \n",
    "    numeric_transformer = Pipeline(steps=[  \n",
    "        ('imputer', SimpleImputer(strategy='median')),  \n",
    "        ('scaler', StandardScaler())])  \n",
    "\n",
    "    # # Define preprocessing for categorical features (encode them)  \n",
    "    categorical_transformer = Pipeline(steps=[  \n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  \n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])  \n",
    "\n",
    "\n",
    "\n",
    "    # Combine preprocessing steps  \n",
    "    preprocessor = ColumnTransformer(  \n",
    "        transformers=[  \n",
    "           ('num', numeric_transformer, numeric_features), \n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "\n",
    "    ]) \n",
    "\n",
    "    # Create preprocessing and training pipeline  \n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),  \n",
    "                               ('regressor', RandomForestRegressor())\n",
    "                              ])  \n",
    "    \n",
    "    try:\n",
    "        df.drop('datetime', axis=1)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # Load your data  \n",
    "    X = df.drop('temperature', axis=1)  \n",
    "    y = df['temperature']  \n",
    "\n",
    "    # Split your data into train and test datasets  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  \n",
    "\n",
    "    # Train model  \n",
    "    pipeline.fit(X_train, y_train)  \n",
    "    \n",
    "    run_id = run.info.run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e239d18-1ef7-4456-b555-3494b2fcd2c5",
   "metadata": {},
   "source": [
    "### Load logged model and verify that data scoring works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3ece3-c58d-4335-81d2-9b76593dd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = f'runs:/{run_id}/model'\n",
    "loaded_model = mlflow.sklearn.load_model(run_path)\n",
    "\n",
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979853a9-60de-4602-be90-186d1fae409a",
   "metadata": {},
   "source": [
    "### Register your newly trained model\n",
    "\n",
    "<i>Note: As part of your standard workflow, you should implement some A/B testing logic to compare the performance of your newly trained model against your previously trained model(s) to ensure performance meets expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585344b-8b37-4b1e-b848-2b5c9b5c0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "run_model = Model(\n",
    "    path=\"azureml://jobs/{}/outputs/artifacts/paths/model/\".format(run_id),\n",
    "    name=\"Temperature_Prediction_Model\",\n",
    "    description=\"Sample regression model from Azure ML model monitoring demo\",\n",
    "    type=AssetTypes.MLFLOW_MODEL\n",
    ")\n",
    "\n",
    "ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b3344-f67a-41c7-a91f-f4c3de179c6a",
   "metadata": {},
   "source": [
    "### Score all weather data and register for post-hoc analysis\n",
    "\n",
    "Here, we score all of our data (training & evaluation), and save into our AML workspace to enable us to run a simulated drift analysis later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ef7e8-670b-4a50-b802-31d1497c1737",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./scored_data', exist_ok=True)\n",
    "\n",
    "dataset_name = 'weather-training-data'\n",
    "data = ml_client.data.get(dataset_name, version='4')\n",
    "dataset = mltable.from_delimited_files(paths=[{'pattern': data._referenced_uris[0]}])\n",
    "df = dataset.to_pandas_dataframe()\n",
    "preds = loaded_model.predict(df)\n",
    "df['Predicted_Temperature'] = preds\n",
    "df.to_csv(f'./scored_data/{dataset_name}_scored.csv', index=False)\n",
    "\n",
    "dataset_name = 'weather-evaluation-data'\n",
    "data = ml_client.data.get(dataset_name, version='4')\n",
    "dataset = mltable.from_delimited_files(paths=[{'pattern': data._referenced_uris[0]}])\n",
    "df = dataset.to_pandas_dataframe()\n",
    "preds = loaded_model.predict(df)\n",
    "df['Predicted_Temperature'] = preds\n",
    "df.to_csv(f'./scored_data/{dataset_name}_scored.csv', index=False)\n",
    "\n",
    "dataset_name = 'weather-full-data'\n",
    "data = ml_client.data.get(dataset_name, version='4')\n",
    "dataset = mltable.from_delimited_files(paths=[{'pattern': data._referenced_uris[0]}])\n",
    "df = dataset.to_pandas_dataframe()\n",
    "preds = loaded_model.predict(df)\n",
    "df['Predicted_Temperature'] = preds\n",
    "df.to_csv(f'./scored_data/{dataset_name}_scored.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3480c-eade-4cb0-8b69-f21aa29f4722",
   "metadata": {},
   "source": [
    "### Upload & register all scored datasets in AML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87db4cb-5945-4e72-8c3b-1aa20a3b95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.fsspec import AzureMachineLearningFileSystem\n",
    "\n",
    "datastore_name = 'workspaceblobstore' # default\n",
    "path_on_datastore = 'weather_data'\n",
    "\n",
    "# long-form Datastore uri format:\n",
    "uri = f'azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/{datastore_name}/paths/'\n",
    "uri\n",
    "\n",
    "# instantiate file system using following URI\n",
    "fs = AzureMachineLearningFileSystem(uri)\n",
    "\n",
    "# you can specify recursive as False to upload a file\n",
    "fs.upload(lpath='./scored_data/weather-training-data_scored.csv', rpath='weather_data/scored_data', recursive=False, **{'overwrite': 'MERGE_WITH_OVERWRITE'})\n",
    "fs.upload(lpath='./scored_data/weather-evaluation-data_scored.csv', rpath='weather_data/scored_data', recursive=False, **{'overwrite': 'MERGE_WITH_OVERWRITE'})\n",
    "fs.upload(lpath='./scored_data/weather-full-data_scored.csv', rpath='weather_data/scored_data', recursive=False, **{'overwrite': 'MERGE_WITH_OVERWRITE'})\n",
    "\n",
    "tbl = mltable.from_delimited_files([{'pattern': uri + 'weather_data/scored_data/weather-training-data_scored.csv'}])\n",
    "tbl.save('./training_data_scored')\n",
    "\n",
    "training_data = Data(\n",
    "    path = './training_data_scored',\n",
    "    type = AssetTypes.MLTABLE,\n",
    "    description = 'January to March 2019 Weather Data',\n",
    "    name='scored-weather-training-data',\n",
    "    version=\"2\"\n",
    ")\n",
    "ml_client.data.create_or_update(training_data)\n",
    "\n",
    "tbl = mltable.from_delimited_files([{'pattern': uri + 'weather_data/scored_data/weather-evaluation-data_scored.csv'}])\n",
    "tbl.save('./eval_data_scored')\n",
    "\n",
    "eval_data = Data(\n",
    "    path = './eval_data_scored',\n",
    "    type = AssetTypes.MLTABLE,\n",
    "    description = 'April to October 2019 Weather Data',\n",
    "    name='scored-weather-evaluation-data',\n",
    "    version=\"2\"\n",
    ")\n",
    "ml_client.data.create_or_update(eval_data)\n",
    "\n",
    "tbl = mltable.from_delimited_files([{'pattern': uri + 'weather_data/scored_data/weather-full-data_scored.csv'}])\n",
    "tbl.save('./full_data_scored')\n",
    "\n",
    "full_data = Data(\n",
    "    path = './full_data_scored',\n",
    "    type = AssetTypes.MLTABLE,\n",
    "    description = 'January to October 2019 Weather Data',\n",
    "    name='scored-weather-full-data',\n",
    "    version=\"2\"\n",
    ")\n",
    "ml_client.data.create_or_update(full_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
