{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97d9ac5-0972-48ee-8d5e-f15e3346346f",
   "metadata": {},
   "source": [
    "# Azure ML Model Monitoring Demo - Offline Monitoring (IN PROGRESS)\n",
    "\n",
    "Series of sample notebooks designed to showcase [AML's continuous model monitoring capabilities](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-model-performance?view=azureml-api-2&tabs=azure-cli). The series of notebooks in this repo have been developed to perform core operations including model training, deployment, simulated production data scoring, and inference data collection. These notebooks have been designed to be run in order and include the following steps:\n",
    "\n",
    "- 00. Data Upload - Load time-series weather data from a local CSV into an AML datastore, and register as training & evaluation datasets\n",
    "- 01. Model Training - Train a custom temperature prediction regression model using Mlflow & Scikit-Learn and register into your AML workspace\n",
    "- 02. Model Deployment - Deploy your newly trained model to a Managed Online Endpoint with production data collection configured.\n",
    "- 03. Production Data Simulation - Send time-series data to your endpoint at a slow rate to simulate production inferencing. All submitted data will be collected automatically.\n",
    "- 04. Monitoring Configuration - Configure a production model data monitor looking for drift in inferencing data, and scored results which can indicate that retraining should be performed.\n",
    "- <b>05. Offline Monitoring - Sample notebook showcasing how to identify drift in data from datasets scored outside of Azure ML.</b>\n",
    "\n",
    "<b>This notebook is designed to showcase data drift monitoring in an offline mode. One capability of model monitoring is the ability to analyze production data scored outside of AML. In this scenario, you will need to register your dataset in AML and then can configure your monitor to analyze continuously updating production datasets. This functionality, and the sample below are based on [this example in Microsoft's documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-model-performance?view=azureml-api-2&tabs=python#set-up-model-monitoring-by-bringing-your-own-production-data-to-azure-machine-learning)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad137721-52cd-4ecd-bb14-c22e541f16d6",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d4ba4-ac66-4b11-b626-ae522dcc9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, Environment, CodeConfiguration, DataCollector, DeploymentCollection\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from mlflow import set_tracking_uri\n",
    "import mlflow\n",
    "\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ai.ml import Input, MLClient\n",
    "from azure.ai.ml.constants import (\n",
    "    MonitorFeatureType,\n",
    "    MonitorMetricName,\n",
    "    MonitorDatasetContext\n",
    ")\n",
    "from azure.ai.ml.entities import (\n",
    "    AlertNotification,\n",
    "    DataDriftSignal,\n",
    "    DataQualitySignal,\n",
    "    DataDriftMetricThreshold,\n",
    "    DataQualityMetricThreshold,\n",
    "    MonitorFeatureFilter,\n",
    "    MonitorInputData,\n",
    "    MonitoringTarget,\n",
    "    MonitorDefinition,\n",
    "    MonitorSchedule,\n",
    "    RecurrencePattern,\n",
    "    RecurrenceTrigger,\n",
    "    SparkResourceConfiguration,\n",
    "    TargetDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ba41c-a887-4ddc-8d5e-42232e17b92d",
   "metadata": {},
   "source": [
    "### Establish connection to Azure ML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013568b4-f278-43ba-83bd-7c89cc19ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<your_subscription_id>\"\n",
    "resource_group = \"<your_resource_group>\"\n",
    "workspace_name = \"<your_workspace_name>\"\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n",
    "workspace = ml_client.workspaces.get(workspace_name)\n",
    "tracking_uri = workspace.mlflow_tracking_uri\n",
    "\n",
    "set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc30768-02b5-4f2c-a4d2-15d7bbcdbf95",
   "metadata": {},
   "source": [
    "### Configure data monitor\n",
    "\n",
    "Here, the two datasets we will use for drift analysis are the `weather-training-data` dataset we used in Notebook 01 to train our model as a baseline, along with the `scored-weather-evaluation-data` dataset we scored with our trained model, and subsequently registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52881dc-2614-441a-8ced-4ac8da97c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_configuration = SparkResourceConfiguration(\n",
    "    instance_type=\"standard_e4s_v3\",\n",
    "    runtime_version=\"3.2\"\n",
    ")\n",
    "\n",
    "#define target dataset (production dataset)\n",
    "input_data = MonitorInputData(\n",
    "    input_dataset=Input(\n",
    "        type=\"mltable\",\n",
    "        path=\"azureml:scored-weather-evaluation-data:1\"\n",
    "    ),\n",
    "    dataset_context=MonitorDatasetContext.MODEL_INPUTS\n",
    ")\n",
    "\n",
    "input_data_target = TargetDataset(dataset=input_data)\n",
    "\n",
    "# training data to be used as baseline dataset\n",
    "input_data_baseline = MonitorInputData(\n",
    "    input_dataset=Input(\n",
    "        type=\"mltable\",\n",
    "        path=\"azureml:weather-training-data:4\"\n",
    "    ),\n",
    "    dataset_context=MonitorDatasetContext.TRAINING\n",
    ")\n",
    "\n",
    "# create an advanced data drift signal\n",
    "features = MonitorFeatureFilter(top_n_feature_importance=20)\n",
    "numerical_metric_threshold = DataDriftMetricThreshold(\n",
    "    applicable_feature_type=MonitorFeatureType.NUMERICAL,\n",
    "    metric_name=MonitorMetricName.JENSEN_SHANNON_DISTANCE,\n",
    "    threshold=0.01\n",
    ")\n",
    "categorical_metric_threshold = DataDriftMetricThreshold(\n",
    "    applicable_feature_type=MonitorFeatureType.CATEGORICAL,\n",
    "    metric_name=MonitorMetricName.PEARSONS_CHI_SQUARED_TEST,\n",
    "    threshold=0.02\n",
    ")\n",
    "metric_thresholds = [numerical_metric_threshold, categorical_metric_threshold]\n",
    "\n",
    "advanced_data_drift = DataDriftSignal(\n",
    "    target_dataset=input_data_target,\n",
    "    baseline_dataset=input_data_baseline,\n",
    "    features=features,\n",
    "    metric_thresholds=metric_thresholds\n",
    ")\n",
    "\n",
    "# create an advanced data quality signal\n",
    "features = MonitorFeatureFilter(top_n_feature_importance=20)\n",
    "numerical_metric_threshold = DataQualityMetricThreshold(\n",
    "    applicable_feature_type=MonitorFeatureType.NUMERICAL,\n",
    "    metric_name=MonitorMetricName.NULL_VALUE_RATE,\n",
    "    threshold=0.01\n",
    ")\n",
    "categorical_metric_threshold = DataQualityMetricThreshold(\n",
    "    applicable_feature_type=MonitorFeatureType.CATEGORICAL,\n",
    "    metric_name=MonitorMetricName.OUT_OF_BOUND_RATE,\n",
    "    threshold=0.02\n",
    ")\n",
    "metric_thresholds = [numerical_metric_threshold, categorical_metric_threshold]\n",
    "\n",
    "advanced_data_quality = DataQualitySignal(\n",
    "    target_dataset=input_data_target,\n",
    "    baseline_dataset=input_data_baseline,\n",
    "    features=features,\n",
    "    metric_thresholds=metric_thresholds,\n",
    "    alert_enabled=\"False\"\n",
    ")\n",
    "\n",
    "# put all monitoring signals in a dictionary\n",
    "monitoring_signals = {\n",
    "    'data_drift_advanced': advanced_data_drift,\n",
    "    'data_quality_advanced': advanced_data_quality\n",
    "}\n",
    "\n",
    "# create alert notification object\n",
    "alert_notification = AlertNotification(\n",
    "    emails=['nick.kwiecien@microsoft.com']\n",
    ")\n",
    "\n",
    "# Finally monitor definition\n",
    "monitor_definition = MonitorDefinition(\n",
    "    compute=spark_configuration,\n",
    "    monitoring_signals=monitoring_signals,\n",
    "    alert_notification=alert_notification\n",
    ")\n",
    "\n",
    "recurrence_trigger = RecurrenceTrigger(\n",
    "    frequency=\"day\",\n",
    "    interval=1,\n",
    "    schedule=RecurrencePattern(hours=3, minutes=15)\n",
    ")\n",
    "\n",
    "model_monitor = MonitorSchedule(\n",
    "    name=\"offline-weather-data-monitoring\",\n",
    "    trigger=recurrence_trigger,\n",
    "    create_monitor=monitor_definition\n",
    ")\n",
    "\n",
    "poller = ml_client.schedules.begin_create_or_update(model_monitor)\n",
    "created_monitor = poller.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
